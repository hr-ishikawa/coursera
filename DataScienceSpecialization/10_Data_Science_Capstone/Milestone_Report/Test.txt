R predict next word
Predict Next Word - RPubs
http://www.rpubs.com/chosengmong/Final_Capstone_Project


Katz-backoffモデル
Good-Turing スムージング

■言語モデル入門 （第二版） - SlideShare
https://www.slideshare.net/yoshinarifujinuma/ss-40451841
◆Kneser-neyスムージング：overview
 •実験的に一番良いスムージング 
 •いくつかバリエーションがある
  – Interpolated Kneser-ney (Kneser & Ney 1995) 
 •今回はこっちを説明
  – Modified Kneser-ney(Chen & Goodman 1999) 
 •アイディアは： –直前の単語の種類数を重視
◆Kneser-neyスムージング：例 
 •Bigram言語モデルを想定 
 •I want to go to Toyama Fransisco
  – Fransiscoは頻度が高いが、ほぼSanの後に続く 
 •スムージング：unigramの頻度
  – P(Toyama Fransisco) ≒ P(Fransisco)
  – P(Toyama Fransisco)が高くなってしまう！ 
 •Kneser-neyのアイディア： –P_continuation: 単語wは直前の単語の種類は 豊富か？
◆パープレキシティ

■[翻訳] text2vec vignette: text2vecパッケージによるテキスト分析
https://qiita.com/nakamichi/items/1bf2ee393cb407d9fb74


Ngram言語モデルメモ
https://jetbead.hatenablog.com/entry/20111031/1320078059
未出現事象の出現確率
https://www.slideshare.net/hirsoshnakagawa3/smoothing1-40918238
言語モデル
http://chasen.org/~daiti-m/paper/naist-dlec2004-lmodel.pdf

Rのtext2vecで次の単語を予測する
https://codeday.me/jp/qa/20190821/1494469.html
単語予測アルゴリズム
https://codeday.me/jp/qa/20190220/270194.html

install.packages("hash")
library(hash)
h <- hash()
h['banana'] <- "banana"
h
h[['banana']] # [1] "banana"

install.packages("openssl")
library(openssl)
sha256("banana") # [1] "b493d48364afe44d11c0165cf470a4164d1e2609911ef998be868d46ade3de4e"

3.3 N-gram モデルのスムージング
ただし，N-gramモデルにおいてはゼロ頻度問題という
問題が存在する．これは、出現頻度により N-gram 確
率を推定すると，学習用データセット中に出現しない単語
組の確率値を 0 としてしまうという問題である．これを
解決するために，線形補間法 というスムージング手法
を用いる．線形補間法は，N-gram 確率 P(wn|w
n−1
n−N+1)
を低次の M-gram(M < N) の確率値と線形に補間する
方法である．N = 2（バイグラム）の場合は，N-gram
確率は次のようになる．
P(wn|wn−1)=λP(wn|wn−1)+(1 − λ)P(wn) (2)
ここで，λ は補間係数であり，経験的に λ = 0.7 と設定す
る．また，N = 3（トライグラム）の場合には，N-gram
確率を次のように書きなおすことができる．
P(wn|wn−2wn−1) = λ3P(wn|wn−2wn−1)
+ λ2P(wn|wn−1)
+ λ1P(wn) (3)
ここで，λ3, λ2, λ1 は，それぞれトライグラム，バイグラ
ム，ユニグラムに対する補間係数であり，∑iλi = 1 と
なるように設定される．これらの補間係数に関しては，
経験的に λ3 = 0.5, λ2 = 0.3, λ1 = 0.2 と設定する．以
降，スムージング手法についてはこれらの補間係数を用
いることとする．


精度予測　データの中からランダムに抽出


install.packages('tidytext')
library(tidytext)

lines <- c('I have a pen.', 'This is a pen.', 'She is a pretty girl.', 'There is a pen in my pocket.')
all <- c('I have a pen.', 
         'This is the 1st dog.',
         'She is a pretty girl.',
         'There is a pen in my pocket.',
         'The quick brown fox jumps over the lazy dog.',
         'I drew this dog picture with this pen')

tkn <- function(lines){
    tibble(line=lines) %>%
    unnest_tokens(word, line) %>%
    filter(str_detect(str_sub(word,1,1),'[a-zA-Z]')) %>%
    anti_join(stop_words, by='word')
}
tkn(lines) %>% group_by(word) %>% summarise(n=n())
# A tibble: 4 x 2
  word       n
  <chr>  <int>
1 girl       1
2 pen        3
3 pocket     1
4 pretty     1

tkn3 <- function(lines){
    tibble(line=lines) %>%
    unnest_tokens(word, line, token='ngrams', n=3)
}
tkn3(lines)

#-----------------------------
tkn <- function(lines){
    tibble(line=lines) %>%
    mutate(line=str_c(lines,' e_o_s')) %>%
    unnest_tokens(word, line) %>%
    filter(str_detect(str_sub(word,1,1),'[a-zA-Z]')) %>%
    anti_join(stop_words, by='word')
}
words <- tkn(lines)
words
# A tibble: 10 x 1
   word  
 1 pen   
 2 e_o_s 
 3 pen   
 4 e_o_s 
 5 pretty
 6 girl  
 7 e_o_s 
 8 pen   
 9 pocket
10 e_o_s 

words %>% filter(!(word %in% c('girl','pocket')))
# A tibble: 8 x 1
  word  
1 pen   
2 e_o_s 
3 pen   
4 e_o_s 
5 pretty
6 e_o_s 
7 pen   
8 e_o_s 


#-----------------------------

#tkns <- bind_rows(tkn(blog),tkn(news),tkn(twtr)) %>% 
tkns <- bind_rows(tkn(blog)) %>% 
    group_by(word) %>% summarise(n=n()) %>% filter(n>1) %>%
    distinct()

trigram <-  tkns %>% 
    mutate(trigram=str_c(word,' ',lead(word),' ',lead(word,2)),nextword=lead(word,3)) %>%
    group_by(trigram,nextword) %>% summarise(n=n()) %>%
    arrange(desc(n))

trigram %>% nrow()
trigram %>% head()
trigram %>% tail()

Q1 <- "When you breathe, I want to be the air for you. I'll be there for you, I'd live and I'd"
x <- tkn(Q1) %>% pull(word) %>% str_c(collapse=' ')
x

trigram %>% filter(trigram==x)
trigram %>% filter(str_detect(trigram,' air live'))
trigram %>% filter(str_detect(trigram,' live$'))
trigram %>% filter(str_detect(trigram,"i'd"))



x <- c('I have a pen.', 'This is a pen.', 'She is a pretty girl.', 'There is a pen in my pocket.')

str_split(x, ' |\\.') %>% unlist()%>% tibble(A=.) %>% mutate(B=lead(A)) %>% 
    filter(A!='') %>% arrange(A,B) %>% group_by(A,B) %>% summarize(N=n())
   A      B          N
   <chr>  <chr>  <int>
 1 a      pen        3
 2 a      pretty     1
 3 girl   ""         1
 4 have   a          1
 5 I      have       1
 6 in     my         1
 7 is     a          3
 8 my     pocket     1
 9 pen    ""         2
10 pen    in         1
11 pocket ""         1
12 pretty girl       1
13 She    is         1
14 There  is         1
15 This   is         1

## 2-words
str_split(x, ' |\\.') %>% unlist()%>% tibble(A=.) %>% mutate(B=lead(A),C=lead(A,2)) %>% 
    filter(A!='',B!='') %>% arrange(A,B,C) %>% group_by(A,B,C) %>% summarize(N=n())

   A      B      C          N
   <chr>  <chr>  <chr>  <int>
 1 a      pen    ""         2
 2 a      pen    in         1
 3 a      pretty girl       1
 4 have   a      pen        1
 5 I      have   a          1
 6 in     my     pocket     1
 7 is     a      pen        2
 8 is     a      pretty     1
 9 my     pocket ""         1
10 pen    in     my         1
11 pretty girl   ""         1
12 She    is     a          1
13 There  is     a          1
14 This   is     a          1

## 3-words
str_split(x, ' |\\.') %>% unlist()%>% tibble(A=.) %>% mutate(B=lead(A),C=lead(A,2),D=lead(A,3)) %>% 
    filter(A!='',B!='',C!='') %>% arrange(A,B,C,D) %>% group_by(A,B,C,D) %>% summarize(N=n())

   A     B      C      D          N
   <chr> <chr>  <chr>  <chr>  <int>
 1 a     pen    in     my         1
 2 a     pretty girl   ""         1
 3 have  a      pen    ""         1
 4 I     have   a      pen        1
 5 in    my     pocket ""         1
 6 is    a      pen    ""         1
 7 is    a      pen    in         1
 8 is    a      pretty girl       1
 9 pen   in     my     pocket     1
10 She   is     a      pretty     1
11 There is     a      pen        1
12 This  is     a      pen        1

library(tidyverse)

df <- tibble( flg=c('AA','AA','AA','AA','AA','AA','AA','AA',
                    'BB','BB','BB','BB','BB','BB','BB','BB' ),
              x  =c(  1,   2,   2,   3,   3,   4,   4,   5,
                      1,   1,   2,   2,   2,   3,   4,   5  ) )

ggplot(df,aes(x=x,fill=flg))+geom_bar(position='identity',width=1,color='black',alpha=0.4)
ggplot(df,aes(x=x,fill=flg))+geom_histogram(position='identity',bins=5,color='black',alpha=0.4)

### ===========================

library(tidyverse)
library(tidytext)

dir <- 'coursera/final/en_US/'

n_max <- 10000L
blog <- read_lines(str_c(dir,'en_US.blogs.txt'  ),locale=locale(encoding='utf8'),skip=0,n_max=n_max) # n_max=Inf
news <- read_lines(str_c(dir,'en_US.news.txt'   ),locale=locale(encoding='utf8'),skip=0,n_max=n_max)
twtr <- read_lines(str_c(dir,'en_US.twitter.txt'),locale=locale(encoding='utf8'),skip=0,n_max=n_max)

#blog <- read_lines(str_c(dir,'en_US.blogs.txt'  ),skip=0,n_max=n_max) # n_max=Inf
#news <- read_lines(str_c(dir,'en_US.news.txt'   ),skip=0,n_max=n_max)
#twtr <- read_lines(str_c(dir,'en_US.twitter.txt'),skip=0,n_max=n_max)

all <- c(blog,news,twtr)
all %>% first() # [1] "In the years thereafter, most of the Oil fields and platforms were named after pagan “gods”."
all %>% last()  # [1] "as of right now at this sec pass me by!"

#----------------
# Strategy
#  Shrink the Data size
#
# Procesedure
# 1) Indicate End of Sentence - The last word don't have following word.
# 2) aggregate the character code to ASCII - some characters are utf8
# 3) filter the word start with alphabets - Other than alphabets are have no sense.
# 4) drop words that appear less frequency - threshold is less equal twice
# 5) n-gram top N pattern - Leave only the top and throw away others, to model to make the model smaller, and too Many candidates are ineffective.


E_O_S <- 'ze_o_Sz' # end of sentence
n_drop <- 2        # Number of frequent words to drop 
rawToUtf <- function(r){str_conv(as.raw(r),encoding='utf8')}

parse_in <- function(lines){ 
    tibble(line=str_c(all,' ',E_O_S)) %>%          # [1] 4,269,678
    unnest_tokens(word,line) %>%                   # Tokenize  [1] "106,671,684"
    filter(str_detect(word,'^[a-zA-Z]')) %>%       # [1] 104,746,113
    mutate(word=str_replace_all(word,rawToUtf(c('0xe2','0x80','0x8e')),''  ),
           word=str_replace_all(word,rawToUtf(c('0xef','0xbb','0xbf')),''  ),
           word=str_replace_all(word,rawToUtf(c('0xe2','0x80','0x98')),'\''),
           word=str_replace_all(word,rawToUtf(c('0xe2','0x80','0x99')),'\''),
           word=str_replace_all(word,rawToUtf(c('0xc3','0xa9')),       'e' ),
           word=str_replace_all(word,rawToUtf(c('0xd0','0xb5')),       'e' ),
           word=str_replace_all(word,rawToUtf(c('0xd0','0xbe')),       'o' ),
           word=str_replace_all(word,rawToUtf(c('0xd1','0x83')),       'y' ),
           word=str_replace_all(word,rawToUtf(c('0xd1','0x95')),       's' ),
           word=str_replace_all(word,rawToUtf(c('0xd1','0x96')),       'i' ) ) %>%
    anti_join(stop_words) %>%                      # [1] 45,430,449
    mutate(word=str_replace(word,'\\\'s$','')) %>% #
    group_by(word) %>% mutate(n=n()) %>% ungroup() %>% 
    filter(n>n_drop) %>%  
    select(-n)
}
words %>% nrow()
words %>% head(15)
words %>% tail(15)

words <- tibble(line=str_c(all,' ',E_O_S)) %>%          # [1] 4,269,678
    unnest_tokens(word,line) %>%                   # Tokenize  [1] "106,671,684"
    filter(str_detect(word,'^[a-zA-Z]')) %>%       # [1] 104,746,113
    anti_join(stop_words) %>%                      # [1] 45,430,449
    mutate(word=str_replace_all(word,rawToUtf(c('0xe2','0x80','0x8e')),''  ),
           word=str_replace_all(word,rawToUtf(c('0xef','0xbb','0xbf')),''  ),
           word=str_replace_all(word,rawToUtf(c('0xe2','0x80','0x98')),'\''),
           word=str_replace_all(word,rawToUtf(c('0xe2','0x80','0x99')),'\''),
           word=str_replace_all(word,rawToUtf(c('0xc2','0xad')),       ''  ),
           word=str_replace_all(word,rawToUtf(c('0xc3','0xa0')),       'a' ),
           word=str_replace_all(word,rawToUtf(c('0xc3','0xa1')),       'a' ),
           word=str_replace_all(word,rawToUtf(c('0xc3','0xa2')),       'a' ),
           word=str_replace_all(word,rawToUtf(c('0xc3','0xa3')),       'a' ),
           word=str_replace_all(word,rawToUtf(c('0xc3','0xa4')),       'a' ),
           word=str_replace_all(word,rawToUtf(c('0xc3','0xa5')),       'a' ),
           word=str_replace_all(word,rawToUtf(c('0xc3','0xa6')),       'a' ),
           word=str_replace_all(word,rawToUtf(c('0xc3','0xa7')),       'c' ),
           word=str_replace_all(word,rawToUtf(c('0xc3','0xa8')),       'e' ),
           word=str_replace_all(word,rawToUtf(c('0xc3','0xa9')),       'e' ),
           word=str_replace_all(word,rawToUtf(c('0xc3','0xaa')),       'e' ),
           word=str_replace_all(word,rawToUtf(c('0xc3','0xab')),       'e' ),
           word=str_replace_all(word,rawToUtf(c('0xc3','0xac')),       'i' ),
           word=str_replace_all(word,rawToUtf(c('0xc3','0xad')),       'i' ),
           word=str_replace_all(word,rawToUtf(c('0xc3','0xae')),       'i' ),
           word=str_replace_all(word,rawToUtf(c('0xc3','0xaf')),       'i' ),
           word=str_replace_all(word,rawToUtf(c('0xc3','0xb1')),       'n' ),
           word=str_replace_all(word,rawToUtf(c('0xc3','0xb3')),       'o' ),
           word=str_replace_all(word,rawToUtf(c('0xc3','0xb4')),       'o' ),
           word=str_replace_all(word,rawToUtf(c('0xc3','0xb6')),       'o' ),
           word=str_replace_all(word,rawToUtf(c('0xc3','0xba')),       'u' ),
           word=str_replace_all(word,rawToUtf(c('0xc3','0xbb')),       'u' ),
           word=str_replace_all(word,rawToUtf(c('0xc3','0xbc')),       'u' ),
           word=str_replace_all(word,rawToUtf(c('0xc4','0x81')),       'a' ),
           word=str_replace_all(word,rawToUtf(c('0xc4','0x87')),       'c' ),
           word=str_replace_all(word,rawToUtf(c('0xc4','0xab')),       'i' ),
           word=str_replace_all(word,rawToUtf(c('0xd0','0xb0')),       'a' ),
           word=str_replace_all(word,rawToUtf(c('0xd0','0xb5')),       'e' ),
           word=str_replace_all(word,rawToUtf(c('0xd0','0xbe')),       'o' ),
           word=str_replace_all(word,rawToUtf(c('0xd1','0x83')),       'y' ),
           word=str_replace_all(word,rawToUtf(c('0xd1','0x95')),       's' ),
           word=str_replace_all(word,rawToUtf(c('0xd1','0x96')),       'i' ), 
           word=str_replace_all(word,rawToUtf(c('0xe1','0xb9','0x87')),'n' ),
           word=str_replace_all(word,rawToUtf(c('0xe1','0xb9','0x9b')),'r' ),
           word=str_replace_all(word,rawToUtf(c('0xe1','0xb9','0xa3')),'s' ),
           word=str_replace_all(word,rawToUtf(c('0xe1','0xb9','0xad')),'t' )) %>%
    mutate(word=str_replace(word,'\\\'s$','')) %>% #
    group_by(word) %>% mutate(n=n()) %>% ungroup() %>% 
    mutate(word=if_else(n>n_drop,word,E_O_S)) %>%       # [1] 104,746,113
    mutate(next_word=lead(word)) %>%
    filter((word!=E_O_S)&(next_word!=E_O_S)) %>%
    select(-n,-next_word)

cat('## nrow(words)',comma(nrow(words)),'\n')  ## nrow(words) 44,847,988

not_ascii <- function(s){str_length(s)!=(charToRaw(s)%>%length())}
CTR  <- function(str){str_c(charToRaw(str),collapse='-')}
CTRN <- function(str){str_split(str,'')[[1]]%>%map_chr(CTR)}

xxz <- words %>%
       group_by(word) %>% summarise(n=n()) %>% 
       mutate(not_ascii=map_lgl(word,not_ascii)) %>% 
       filter(not_ascii==TRUE) %>% arrange(desc(n))
xxz %>% head(10)
xxx <- xxz %>% pull(word) # %>% sort()
xxx %>% length() #321
x <- xxx[1];x;CTR(x);CTRN(x)
x <- xxx[2];x;CTR(x);CTRN(x)
x <- xxx[3];x;CTR(x);CTRN(x)

x <- str_sub(xxx[2],6,6);x;CTR(x);CTRN(x)

#----------------------------------
# n-gram

n_words <- table(words$word)

system.time(  #  103.92       3.41     107.40 
unigram <- 
  words %>%
    mutate(words    =word,
           next_word=lead(word)) %>% 
    select(-word) %>%
    filter(!str_detect(words,    E_O_S) &
           !str_detect(next_word,E_O_S)  ) %>%
    group_by(words,next_word) %>% summarize(n=n()) %>% ungroup() %>%
    group_by(words) %>% top_n(1,n) %>% ungroup() %>% mutate(n=n_words[next_word]) %>%
    arrange(desc(n)) %>% distinct(words, .keep_all=T) %>%
    select(-n)
)
cat('## nrow(unigram)',comma(nrow(unigram)),'\n')
cat('## object.size(unigram)',comma(object.size(unigram)/1000000),'MB \n')
unigram %>% head(10)

system.time( #      1962.66      13.89    1976.69 
bigram <- 
  words %>%
    mutate(words    =str_c(word,' ',lead(word)),
           next_word=lead(word,2)) %>% 
    select(-word) %>%
    filter(!str_detect(words,    E_O_S) &
           !str_detect(next_word,E_O_S)  ) %>%
    group_by(words,next_word) %>% summarize(n=n()) %>% ungroup() %>%
    group_by(words) %>% top_n(1,n) %>% ungroup() %>% mutate(n=n_words[next_word]) %>%
    arrange(desc(n)) %>% distinct(words, .keep_all=T) %>%
    select(-n)
)
cat('## nrow(bigram)',comma(nrow(bigram)),'\n')
## nrow(bigram) 18,221,405 
cat('## object.size(bigram)',comma(object.size(bigram)/1000000),'MB \n')
## object.size(trigram) 3642.7 bytes MB 
bigram %>% head(10)

system.time(  #     5829.5      109.6     6052.4 
trigram <- 
  words %>%
    mutate(words    =str_c(word,' ',lead(word),' ',lead(word,2)),
           next_word=lead(word,3)) %>% 
    select(-word) %>%
    filter(!str_detect(words,    E_O_S) &
           !str_detect(next_word,E_O_S)  ) %>%
    group_by(words,next_word) %>% summarize(n=n()) %>% ungroup() %>%
    group_by(words) %>% top_n(1,n) %>% ungroup() %>% mutate(n=n_words[next_word]) %>%
    arrange(desc(n)) %>% distinct(words, .keep_all=T) %>%
    select(-n)
)
cat('## nrow(trigram)',comma(nrow(trigram)),'\n')
## nrow(trigram) 38,256,211 
cat('## object.size(trigram)',comma(object.size(trigram)/1000000),'MB \n')
## object.size(trigram) 3642.7 bytes MB 
trigram %>% head(10)
#----------------------
# create ngram
# First, try trigram. If not match fall back to low gram.



words %>% arrange(word) %>% head(15)
words %>% arrange(word) %>% tail(15)

## str_detect(c('AA','1A','&A','bA',' A','-A','_A','.A'),'^[a-zA-Z]')

table(words$word) %>% as.integer() %>% summary()
Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
1.00     1.00     2.00     8.44     4.00 30000.00 
table(words$word) %>% as.integer() %>% map_lgl(function(x){x==1}) %>% sum() # [1] 22489
table(words$word) %>% as.integer() %>% map_lgl(function(x){x>2})  %>% sum() # [1] 16835

### utf8

charToRaw('\'') # [1] 27
charToRaw('’')  # [1] 81 66
charToRaw(iconv('’', from='CP932', to='utf-8')) # [1] e2 80 99
charToRaw(iconv('’', from='CP932', to='ascii')) # [1] 4e 41 <- [1] NA

CTR <- function(str){str_c(charToRaw(str),collapse='-')}
CTR('AA') # [1] "41-41"
tibble(line=str_c(all,' ',E_O_S)) %>% unnest_tokens(word,line) %>%
filter(str_detect(word,'’')) %>% mutate(word=map_chr(word,CTR))
#word                               
#1 74-68-65-79-e2-80-99-72-65         
#2 63-61-6e-e2-80-99-74               

tibble(line=str_c(all,' ',E_O_S)) %>% unnest_tokens(word,line) %>%
filter(str_detect(word,'’'))
#word      
#1 they’re   
#2 can’t 

 
tibble(line=str_c(all,' ',E_O_S)) %>% unnest_tokens(word,line) %>%　filter(str_detect(word,'’')) %>% nrow() # [1] 4934

words %>% mutate(word=str_replace(word,'’','')) %>% filter(str_detect(word,'’')) ## A tibble: 0 x 1
words %>% mutate(word=str_replace(word,'’','')) %>% filter(str_detect(word,'can\'t')) %>% nrow()

words %>% mutate(word=str_replace(word,'’','\'')) %>% filter(str_detect(word,'’')) ## A tibble: 0 x 1
words %>% mutate(word=str_replace(word,'’','\'')) %>% filter(str_detect(word,'\'')) ## # A tibble: 17,842 x 1
words %>% mutate(word=str_replace(word,'’','\'')) %>% filter(str_detect(word,'can\'t')) %>% nrow()


###----------------------
> TestData <- c("Karada-Good", "カラダニ、いいもの", "111-111-1111",
+               "Name:からだに、いいもの", "統計")
> str_conv(string = TestData, encoding = "ISO-8859-1")
[1] "Karada-Good"                                                                
[2] "\u0083J\u0083\u0089\u0083_\u0083j\u0081A\u0082¢\u0082¢\u0082à\u0082Ì"   
[3] "111-111-1111"                                                               
[4] "Name:\u0082©\u0082ç\u0082¾\u0082É\u0081A\u0082¢\u0082¢\u0082à\u0082Ì"
[5] "\u0093\u009d\u008cv"                                                        

◆文字列をエンコーディングする
x <- rawToChar(as.raw(177))
charToRaw(x) # [1] b1
x # [1] "ｱ"
## [1] "ｱ"
str_conv(x, "ISO-8859-2") # Polish "a with ogonek" # [1] "ą"
## [1] "<U+0105>"
str_conv(x, "ISO-8859-1") # Plus-minus # [1] "±"
## [1] "±"

rawToChar(c(as.raw(65),as.raw(65))) # [1] "AA"

not_ascii <- function(s){str_length(s)!=(charToRaw(s)%>%length())}
CTR <- function(str){str_c(charToRaw(str),collapse='-')}
xxx <- words %>% mutate(not_ascii=map_lgl(word,not_ascii)) %>% 
                 filter(not_ascii==TRUE) %>% pull(word)
xxx %>% map_chr(CTR)
#  [1] "61-69-6e-e2-80-99-74"                      "61-6c-7a-68-65-69-6d-65-72-e2-80-99-73"   
# ...
# [15] "62-72-69-74-61-69-6e-e2-80-99-73"          "63-61-66-c3-a9"                
 
xxx[16] # [1] "café"
xxx[16] %>% charToRaw() # [1] 63 61 66 c3 a9

xxx[16] %>% str_conv(encoding='ISO-8859-1') # [1] "cafÃ©"
xxx[16] %>% str_conv(encoding='ISO-8859-1') %>% charToRaw() # [1] 63 61 66 c3 83 c2 a9

charToRaw(xxx[16]) # [1] 63 61 66 c3 a9
charToRaw(str_sub(xxx[16],4,4)) # [1] c3 a9
str_conv(xxx[16],encoding='utf8') # [1] "café"
str_conv(xxx[16],encoding='utf8') %>% charToRaw() # [1] 63 61 66 c3 a9
str_conv('é',encoding='utf8') # [1] "e"
str_conv('é',encoding='utf8') %>% charToRaw # [1] 65
str_conv('é',encoding='utf8') %>% charToRaw # [1] 65
str_conv(str_sub(xxx[16],4,4),encoding='utf8') %>% charToRaw() # [1] c3 a9

str_detect(xxx[16],'é') # [1] FALSE

str_detect(xxx[16],'c') # [1] TRUE
str_detect(xxx[16],'e') # [1] FALSE
str_detect(xxx[16],'é') # [1] FALSE
str_detect(xxx[16],'\uc3a9') # [1] FALSE
str_detect(xxx[16],str_sub(xxx[16],4,4)) # [1] TRUE

rawToChar(c(as.raw(0xc3),as.raw(0xa9))) # [1] "ﾃｩ"
charToRaw(rawToChar(c(as.raw(0xc3),as.raw(0xa9)))) # [1] c3 a9
charToRaw(str_sub(xxx[16],4,4)) %>% rawToChar() # [1] "ﾃｩ"
charToRaw(str_sub(xxx[16],4,4)) %>% rawToChar() %>% str_conv(encoding='utf8') # [1] "é"

charToRaw(rawToChar(as.raw(c(0xc3,0xa9)))) %>% str() # raw [1:2] c3 a9
charToRaw(str_sub(xxx[16],4,4)) %>% str()            # raw [1:2] c3 a9

charToRaw(rawToChar(as.raw(c(0xc3,0xa9)))) %>% rawToChar() %>% str_conv(encoding='utf8') # [1] "é"
charToRaw(str_sub(xxx[16],4,4))            %>% rawToChar() %>% str_conv(encoding='utf8') # [1] "é"

as.raw(c(0xc3,0xa9)) %>% rawToChar() %>% str_conv(encoding='utf8') # [1] "é"
as.raw(c(0xc3,0xa9)) %>% str_conv(encoding='utf8') # [1] "é"
c('0xc3','0xa9') %>% as.raw() %>% str_conv(encoding='utf8') # [1] "é"
str_conv(as.raw(c(0xc3,0xa9)),encoding='utf8') # [1] "é"

rawToUtf <- function(r){str_conv(as.raw(r),encoding='utf8')}
rawToUtf(c('0xe2','0x80','0x99')) # [1] "’"
rawToUtf(c('0xc3','0xa9')) # [1] "é"


str_detect(xxx[ 1],str_conv(as.raw(c(0xe2,0x80,0x99)),encoding='utf8')) # [1] TRUE
str_detect(xxx[16],str_conv(as.raw(c(0xc3,0xa9)),encoding='utf8'))      # [1] TRUE



#================================
shiny
【R Shiny】fileInputメソッドでファイルアップロード
https://www.randpy.tokyo/entry/shiny_16

ui.R
shinyUI(
  fluidPage(
    sidebarLayout(
      sidebarPanel(
        #=====================================
        fileInput("file",                     #<= 変数名
                  "Choose CSV File",          #<=
                  accept = c("text/csv","text/comma-separated-values,text/plain",".csv")
        #=====================================
        ),
        tags$hr(),
        h2("プロットするデータを選択"),
        htmlOutput("colname1"),
        htmlOutput("colname2"),
        actionButton("submit", "プロット")
      ),
      mainPanel(
        tabsetPanel(type = "tabs",
                    tabPanel("Table", tableOutput('table')),
                    tabPanel("Plot", plotOutput("plot"))
        )
      )
    )
  )
)

server.R
server = function(input, output, session) {
  observeEvent(input$file, {
    
    #==============================================
    csv_file = reactive(read.csv(input$file$datapath))
    #==============================================
    output$table = renderTable(csv_file())
    
    output$colname1 = renderUI({ 
      selectInput("x", "x軸方向", colnames(csv_file()))
    })
    output$colname2 = renderUI({ 
      selectInput("y", "y軸方向", colnames(csv_file()))
    })
  })
  
  observeEvent(input$submit, {
    name = names(input$file)
    csv_file = reactive(read.csv(input$file$datapath))
    
    x = csv_file()[input$x]
    y = csv_file()[input$y]
    
    output$plot = renderPlot({
      plot(x[,1], y[,1])
    })
  })
}




